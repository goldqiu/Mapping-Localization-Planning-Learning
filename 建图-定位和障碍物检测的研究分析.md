# 前言

在实验室的室外AMR系统中，要实现运动规划的功能，”感知“是其中的基础部分。由于感知在自动驾驶是独立的一部分，且大部分是基于深度学习去实现的，不太符合现阶段AMR系统要实现的功能，或者说现阶段的AMR系统不需要高智能水平的感知功能，只需要障碍物检测功能即可。故这里把感知分为**SLAM和障碍物检测**，其中SLAM分为定位和建图，那么感知就包含**定位、建图、障碍物检测**（处理点云和图像）三大块，如下图：

![picture-1](.\pic\picture-1.png)

下面为定位、建图和障碍物检测的研究和分析，目前的主要工作包括感知系统方案、SLAM算法分析、SLAM定位工程实现，基于此文总结的方案见PPT。

# SLAM算法分析

## SLAM论文的另一角度分类

目前的SLAM论文还可做这样的一个分类，即是**侧重于建图还是侧重于定位**。

### 侧重于建图

如果说是侧重于建图，那么目的就是为了建好一个地图，其中考虑鲁棒性、效率等。其建图整体流程如下图：

![picture-2](.\pic\picture-2.png)

示例论文：其关键词是**里程计和建图**（里程计中涵盖定位功能，是为了拼接地图）

LIO-SAM: Tightly-coupled Lidar Inertial **Odometry** via Smoothing and **Mapping**

FAST-LIO: A Fast, Robust LiDAR-inertial **Odometry** Package by Tightly-Coupled Iterated Kalman Filter

这种类型的SLAM的定位功能主要是为建图服务的，比如前端里程计的NDT实现，就是一种**局部的建图定位**，是为了更好的进行点云拼接。

那么建图整体流程中是这么体现的：

![picture-3](.\pic\picture-3.png)

### 侧重于定位

如果说是侧重于定位，那么主要工作是**场景识别place recognition**，其建图主要是为了定位服务，比如实时建立局部地图（注：这里其实也有定位，因为建图还是需要有为建图服务的定位，可称之为局部建图定位）和全局地图进行匹配，并定位，且要变换到全局坐标系，所以这里的定位其实应该指的是**全局定位**。

示例论文：其关键词是定位或重定位、场景识别

Tightly-Coupled Multi-Sensor Fusion for **Localization** with LiDAR Feature Maps

LiDAR-Based Initial Global **Localization** Using Two-Dimensional (2D) Submap Projection Image 

Range Image-based LiDAR **Localization** for Autonomous Vehicles

Rover **Relocalization** for Mars Sample Return by Virtual Template Synthesis and Matching

A Hierarchical Dual Model of Environment and Place-Specific Utility for Visual **Place Recognition**

### 总结：

**不管是侧重于建图还是侧重于定位的SLAM，其进行机器人的状态估计可以说是为了实现定位功能，只是侧重于建图的SLAM，定位是为了拼接地图；而侧重于定位的SLAM，更多是说在全局地图下的定位。**

## SLAM之建立地图

基于侧重于建图的SLAM，有建图流程图如下：

![picture-4](.\pic\picture-4.jpg)

### 前端里程计实现

#### 直接匹配法：

##### ICP（迭代最近邻点Iterative Closest Point）

![picture-5](.\pic\picture-5.jpg)

##### NDT(正态分布变换Normal Distribution Transformation)

![picture-6](.\pic\picture-6.jpg)

**注：这里NDT也有用在路径规划中**

#### 基于特征法

##### LOAM系列

1. 提取特征 

1) 按线数分割

2) 计算曲率

3) 删除异常点

4) 按曲率大小筛选特征点

2. 帧间匹配 

1) 特征关联与损失函数计算 

a. 线特征

b. 面特征

2) LM迭代优化

3. 构建地图 

1) 合并地图点

2) 注：**位姿优化与里程计的方法是同理的，即前端和后端都是匹配优化的问题。**

### 后端优化

目的：利用回环检测结果和惯导先验位姿修正里程计误差。回环在此处提供的是两帧之间的相对位姿。

观测包括：

1) 连续两帧的相对位姿观测 

2) 闭环匹配得到的相对位姿观测 

3) 组合导航提供的先验位姿观测

1)和2)的观测构成了基于回环的位姿修正 

1)和3)的观测构成了基于先验观测的位姿修正 

1) 2) 3) 可以同时使用。

### 建图的总结

**不论是前端匹配还是后端优化，其核心原则是准确、高效地把里程计相对位姿、回环相对位姿、惯导先验位姿进行融合；鲁棒性可以由多传感器融合来提高，其效率可以由改变实现方法来提高，比如采用滑动窗口、滤波代替优化、优化采用增量优化的方法。这个过程属于机器人状态估计的过程，其精确位姿的生成就是一个定位过程，并不断在优化后精确位姿的基础下进行地图叠加。**

**所以说为什么SLAM是一个状态估计问题，因为不论是侧重于建图还是侧重于定位，都是要先进行机器人自身的状态估计，其主要区别是侧重于定位的SLAM重点是在解决全局地图上的全局定位问题。**

## SLAM之定位

重定位、回环检测和全局定位都是找到地图中与当前帧匹配的关键帧，这一步称为**场景识别place recognition**；找到匹配帧后还需要通过时间序列匹配等方法去除误匹配；最后可以对帧与帧进行姿态解算。

对于激光SLAM,**可使用3D-3D方法求得当前帧在世界坐标系的位姿，具体有ICP和NDT**。对于视觉SLAM中，可以使用ORB的BoW方法实现快速的重定位、回环检测和全局定位。

### 重定位

指在跟踪丢失后，累积漂移较小。通过重定位获得当前帧在世界坐标系的位姿，当前帧的位姿一般在丢失前的最新帧附近，随着丢失时间的增长，离丢失位姿会越来越远。

### 闭环检测

是跟踪未丢失，但由于时间和空间距离较长，累积漂移较大。漂移越大，当前帧位姿越不准确。闭环检测通过找到历史时间的闭环帧(漂移相对当前帧小)减少漂移。从滤波的角度可以直观的理解，开环情况下不确定性会不断增大，发现闭环后当前帧可以建立和较久以前闭环帧的联系，当前帧不确定性减小，不确定性又从闭环帧开始增加。卡尔曼滤波的马尔可夫性，当前状态只与前一状态相关，非线性优化中当前状态和之前相关联的所有状态相关。

### 全局定位

一般指在开机后在建好的地图上定位，此时当前帧的位姿可能出现在已有地图中的任意位姿，甚至已有地图之外。**有时也可以人为给定大致的初始位姿或者最后开机和关机的位置是确定的。为了更加通用，通常考虑初始位姿完全未知的情况。**

注：这里概念有点混淆，其实就是解决场景识别问题。**把在路径规划中需要提供定位信息称之为全局定位，把slam中为建图服务的定位称为建图定位（局部）；回环检测就还是回环检测，是全局一致性的一个很好的优化策略。重定位是属于解决跟踪丢失的问题。**

## 基于全局地图的定位（全局定位）：

### 基于点云地图的定位

#### 基于ICP或NDT

定位流程图如下：

![picture-7](.\pic\picture-7.jpg)

由于匹配需要较准确的初始位姿，因此在定位之前需要初始化环节，给出载体的初始位姿。 

按照难度由低到高，常见的初始化需求有这样几种： 

1)   已知位姿的初始化 

2）位置已知而姿态未知的初始化 

**3）位置和姿态均未知的初始化**

第三种是最通用也是最难的一种情况。



#### Scan Context

Scan Context:Egocentric Spatial Descriptor for Place Recognition Within 3D Point Cloud Map

常用于场景识别，搜索大范围。

#### 基于特征

##### Tightly-Coupled Multi-Sensor Fusion for Localization with LiDAR Feature Maps

涉及激光特征地图的生成，有特征数据的保存。

要进行在线定位，应提前构建可扩展的高精度地图。

地图包含三种特征：边缘特征、表面特征和 3D 分布。与稀疏 3D 点云或 NDT 地图相比，我们的地图同时包含几何特征（边缘和表面）和 3D 正态分布特征，使我们的方法能够获得稳健而准确的特征关联。

地图生成包含以下三个步骤：
LiDAR 姿态生成：我们使用基于图优化的离线 SLAM 框架来完全融合来自各种传感器的观察结果，包括具有后处理功能的高精度 GNSS 数据、IMU、车轮编码器、和两个 LiDAR，以生成准确的 LiDAR 姿势。离散激光扫描与 LiDAR 姿态对齐，以生成具有全局一致性的点云图。由于 LiDAR 姿态的生成超出了这项工作的范围，我们将忽略具体细节。
点云不失真：在连续时间戳之间均匀运动的假设下，我们使用 IMU 和车轮编码器提供的运动预测作为运动模型来不失真点云。
特征图的参数化：在获得全局一致的点云图后，我们从密集点云图中提取显着的 LiDAR 特征。
首先我们将点云图划分为体素，并计算每个体素的均值和协方差矩阵。
然后我们通过计算协方差矩阵的特征值将体素分类为边缘、表面或正态分布特征，具体来说，具有两个小特征值和一个大特征值表示边缘特征；有一个小两个大特征值表示表面特征；否则表示正态分布特征。
最后，直线方程特征、表面特征的法向量、均值和计算正态分布特征的协方差矩阵分别参数化相应的体素。

### 基于range images地图的定位：

Range Image-based LiDAR Localization for Autonomous Vehicles

波恩大学Cyrill Stachniss 团队的range-mcl框架

PointCloud->Range Image 激光雷达点云到深度图像

基于蒙特卡罗定位和粒子滤波，来估计移动机器人或自动驾驶汽车的姿态，以实现全局定位。 传感器模型将当前激光雷达扫描的距离图像，还有三角网格渲染的合成距离图像，进行比较，更新粒子的权重。该方法简单有效，可以在不同的数据集和环境中使用不同类型的激光雷达扫描，无需微调。  并且在动态的室外大范围环境中取得良好的全局定位结果。

### 基于Surfel地图的定位

地理数据网格化地图

### 补充：

基于学习的方法通过训练已有数据在未知的环境中进行定位：Learning to Localize in New Environments from Synthetic Training Data

## 滤波和优化框架的区别

![picture-8](.\pic\picture-8.jpg)

图里一共三行，第一行是优化，第二行是基于滑动窗口的优化，第三行是滤波。

因此可以简单地认为，“滤波就是窗口长度为1的滑动窗口优化”。推导滤波和优化的公式，会发现滤波与滑动窗口具有同样的理论基础甚至推导步骤，所以“滤波就是窗口长度为1的滑动窗口优化”这句话并不是近似描述，而是在数学上严格成立的。

在这种情况下，在设计融合时，应该首选优化，当计算资源受限时，降低窗口的宽度即可，大不了降低到1，实现和滤波一样的效果（由于实现方式不同，长度为1的滑动窗口实际上会比滤波的计算量大一些）。

# 障碍物检测算法分析

Occupancy grid map和Voxel map后，进行障碍物检测

# SLAM定位工程实现

## 2022年3月21日定位测试

### 基于lio-sam的定位

#### 跑官方数据集

![picture-9](.\pic\picture-9.png)

#### 跑机电楼下

两个不同数据集的使用，一个数据集生成地图，一个数据集进行定位。

![picture-10](.\pic\picture-10.png)

#### 跑二楼平台

两个不同数据集的使用，一个数据集生成地图，一个数据集进行定位。

![picture-11](.\pic\picture-11.png)

相同数据集的使用，一个数据集生成地图并进行定位。

![picture-12](.\pic\picture-12.png)

### 基于livox-relocalization的定位

#### 跑二楼平台

相同数据集的使用，一个数据集生成地图并进行定位。

![picture-13](.\pic\picture-13.png)

两个不同数据集的使用，一个数据集生成地图，一个数据集进行定位。

![picture-14](.\pic\picture-14.png)

### 重构SLAM的框架跑kitti数据集

![picture-15](.\pic\picture-15.png)

![picture-16](.\pic\picture-16.png)

这个重构的SLAM框架代码是基于现有的SLAM算法重构而成，即可用于建图和又可用于定位，前端用了NDT做里程计，后端采用了scan-to-map和回环、全局约束的优化，这部分可以用于建图，在kitti数据集下生成地球坐标系下的全局地图；由于kitti数据集包含了全局卫星信息，是位置已知而姿态未知的初始化情况，定位用了ICP匹配实现全局定位。

### 总结

**室外进行定位需要加全局约束即GNSS卫星定位，然后进行建图，这时的地图才是全局地图；定位的同时也需要有全局约束，才是全局地图下的定位。**

**假设一种情况，我在全局地图的不同位置和方向（姿态）进行启动，如何匹配上全局地图。这时，全局定位的位置定位比较容易实现，但是姿态如何初始化还需要考虑，并且进行实地测试。**

## 2022年3月22日定位测试

实验一（20220322-2.mp4）：测试LIO-SAM_based_relocalization定位框架，数据集场景为机电楼楼下，在大约运行了bag包8s后运行该定位程序（其中没有暂停bag包），可以正常定位。在21秒时暂停bag包，重启该定位程序，发现定位失败，提示：offer a new guess please。重新做一次实验，在21秒时没有暂停bag包，直接运行定位程序，定位失败。

怀疑是操作不当，因为不暂停播放bag包直接开启定位程序，和暂停播放后开启定位程序再播放不太一样，后者先进行了导入地图的操作。为避免导入地图的时间影响定位，于是采用暂停播放后开启定位程序再播放再测试一遍，大约20s后暂停，开启定位程序后，等待一会后播放，还是定位失败。

实验二（20220322-3.mp4）：测试LIO-SAM_based_relocalization定位框架，数据集场景为二楼平台

后面基本是采用暂停播放后开启定位程序再播放，测试8秒左右开启定位程序，能够正常定位。于是再延长时间到30s左右，此时并没有报错，也有在匹配，但是定位还是失败的，出现大角度偏转。

 实验三（20220322-4.mp4）：测试重构slam框架中定位功能，数据为kitti数据集。

测试20秒左右开启定位程序，直接大幅度漂，定位明显失败

 实验四（20220322-5.mp4）：测试重构slam框架中定位功能，数据为kitti数据集。

测试7秒左右开启定位程序，开始还是不飘的，后面在路口前面就提前拐弯了。这里的原因是初始值的问题。

![picture-17](.\pic\picture-17.png)

实验五（20220322-6.mp4）：测试重构slam框架中定位功能，数据为kitti数据集。

直接开启bag跑，看下长时间效果，没什么问题。

![1647902471(1)](L:\寒假备份\组会汇报\汇报数据\1647902471(1).jpg)

 实验六（20220322-7.mp4）：测试重构slam框架中定位功能，数据为kitti数据集。

后面发现在播放bag指令后面加-s可以进行数据播放延迟，可以先开启程序再执行延时后的bag包播放，但其实跟采用暂停播放后开启定位程序再播放一样的道理，还是再进行测试了。

延时20s，还是定位失败。

实验七（20220322-8.mp4）：测试LIO-SAM_based_relocalization定位框架，数据集场景为二楼平台

延时20秒，定位失败，但没报错，跟实验二的现象一样。

实验八（20220322-9.mp4）：测试livox雷达官方定位框架，数据集场景为二楼平台

延时20秒，定位成功

![1647902749(1)](L:\寒假备份\组会汇报\汇报数据\1647902749(1).jpg)

实验九（20220322-10.mp4）：测试livox雷达官方定位框架，数据集场景为机电楼楼下

延时20s，定位失败。后面测试不延时，也是定位失败，具体原因不明。

实验十（20220322-11.mp4）：测试LIO-SAM_based_relocalization定位框架，数据集场景为机电楼楼下

不延时，直接运行，长时间可以定位，拐弯也正常。

![1647902962(1)](L:\寒假备份\组会汇报\汇报数据\1647902962(1).jpg)

实验十一（20220322-12.mp4）：测试LIO-SAM_based_relocalization定位框架，数据集场景为机电楼楼下

延时20s运行，定位失败。

## 两天的实验总结

1. 从第一天的测试可以得知，如果采用同个数据集在同个数据产生的地图中进行定位测试（这天还没想到可以延时播放），这样的定位是没有多大实际意义的。**采用不同数据集在不同数据产生的地图中进行定位，发现自己录的数据集无法定位，方向大幅度偏转**。这里的原因是**没有加全局定位约束，包括全局地图和实时建图**。kitti数据集没有进行这样的测试是因为找不到同个场景的不同数据集。
2. 第二天是想到了延时播放，一定程度上模仿实际情况的定位，但也有所有不同，比如说，实际情况下，往往是AMR先静止不动，先在场景中定位后再进行规划。而延时播放是只确保先导入了地图后再播放，但是此时没有静止先定位，有运动。**后面返校进行实际场景地图的定位测试除了录制全局定位下的地图，全局定位下的动态数据包，还需要静止数据包进行定位测试**。目前居家没有条件，可以通过提取延时播放的那一帧数据与全局地图进行定位匹配，如果说能够匹配上，则说明**场景内任意位姿下的全局定位**是有效的（这就相当于是接近静止了，但是也不太可靠，可以先这样做）
3. 通过对第二天的大量测试中，对于LIO-SAM_based_relocalization定位包，在两个测试场景包括官方数据集，在没有延时的情况下，都能够相对长时间定位，顺利拐弯（50s以上），但是延时一段时间进行播放是无法定位的，这里的原因猜测有二：一是在任意位置进行全局定位需要一定时间下静止初始化（个人觉得起码得3s以上），二是**该定位包并没有编写位置和姿态均未知的初始化，直接不延时播放相同数据的bag包能定位是因为把第一帧当作初始位姿了。换成不相同数据的bag包就不行了，因为没有进行全局定位。但是就算进行了全局定位，如果没有进行编写位置和姿态均未知下的初始化，也需要给定初值（比如在相同位置进行启动）。**就算第二点猜测都满足了，不论是编写位置和姿态均未知下的初始化还是给定初值，对于数据集而言，第一点问题还是存在，这原因就是前面讲的，数据集播放和实际应用不一样，没有静止初始化的步骤。**需要去看代码或者实际测试，看有没有编写位置和姿态均未知下的初始化，大概率是没有的。**
4. 对于livox官方定位包，出现了很奇怪的情况，在场景比较小的二楼平台中，不论延时还是不延时播放，都能正常定位。但是在场景比较大的机电楼楼下，是不能正常定位的。**猜测是因为固态雷达FOV小的原因，建图还可以，但是要是用来定位不够鲁棒，需要有多个固态雷达。所以目前来说用机械式雷达来做AMR整体大范围的定位是比较合理的。而固态雷达用作建图的补充和主要是对障碍物的检测和凹凸地面的检测。**具体还需要实际测试。
5. 对于重构的slam包，建图是没有太大问题的，可以添加不同框架下的建图，但是定位跟LIO-SAM_based_relocalization定位包是一样的问题，代码已知是没有编写位置和姿态均未知下的初始化，所以问题类似。

综上：需要解决鲁棒性的定位问题，首先要加**全局约束**，然后需要编写**位置和姿态均未知下的初始化**，类似于回环，但又复杂于回环。同时实际测试和数据集需要考虑周全。



# **障碍物检测工程实现**

考虑Occupancy grid map和Voxel map进行障碍物检测，地面检测

可以加相机

单线激光雷达进行障碍物检测的信息补充

点云或图像处理、检测大小

针对点云：考虑帧率

一帧：感知的距离

几帧：感知的轮廓

看move_base，有提供单线雷达数据，用做？

# AMR感知系统的信息提供策略

点云层：定位和障碍物检测

三维栅格或者voxel层：定位和障碍物检测

2.5d栅格层 ：先计算梯度，地面的高度代价作为二维层的先验

二维层 ：要把定位信息跟障碍物信息（局部规划）、地面高度信息给到这个层

二维全局代价地图

参考move_base发布的消息

# 感知系统方案

感知系统方案示意图为：

![图片2](L:\寒假备份\组会汇报\汇报数据\图片2.png)



注：障碍物检测和硬件授时并未完善，同时定位与建图的细化也没体现。



# 后续

## 现在工作：

障碍物检测和信息怎么提供，参考move_base

定位看一下比较好的方法。

## 后面方向：

多机考虑定位，多机的状态估计

单机的定位